{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5a2bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (907485, 16)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in csv \n",
    "df = pd.read_csv('data/df_final_2023_08_25')\n",
    "# shape \n",
    "print(\"Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50b4cd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the printing size of the pandas df: \n"
     ]
    }
   ],
   "source": [
    "print(\"Set the printing size of the pandas df: \")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562b0e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the discontious SCC where period_index==-1\n",
      "Shape:  (907485, 16)\n",
      "Shape:  (671868, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Deleting the discontious SCC where period_index==-1\")\n",
    "print(\"Shape: \", df.shape)\n",
    "df = df[df[\"period_index\"] != -1]\n",
    "print(\"Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63266edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift scc to the first column\n"
     ]
    }
   ],
   "source": [
    "print(\"Shift scc to the first column\")\n",
    "# shift column 'scc' to first position\n",
    "first_column = df.pop('scc')\n",
    "# insert column using insert(position,column_name, first_column) function\n",
    "df.insert(0, 'scc', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f7e1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For convinent, make milkng_date the string\n"
     ]
    }
   ],
   "source": [
    "print(\"For convinent, make milkng_date the string\")\n",
    "milkng_date_only = df['milkng_date'].apply(lambda x: str(x))\n",
    "df['milkng_date_only'] = milkng_date_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d949b",
   "metadata": {},
   "source": [
    "# Pre-processing (de-trending, normalize cow, dataset chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4283002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingore future warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "# surprass chain warning\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a758f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the id of the herds: \n",
      "40 [4, 50, 29, 34, 47, 9, 45, 31, 2, 30, 15, 19, 23, 42, 5, 7, 38, 40, 20, 36, 21, 39, 1, 8, 10, 18, 32, 25, 3, 22, 11, 41, 27, 6, 0, 14, 49, 37, 28, 26]\n"
     ]
    }
   ],
   "source": [
    "print(\"All the id of the herds: \")\n",
    "print(len(df[\"hrd_ida\"].unique().tolist()), df[\"hrd_ida\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634bc4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescale and bucket the scc value\n"
     ]
    }
   ],
   "source": [
    "print(\"Rescale and bucket the scc value\")\n",
    "\n",
    "def conditions(i): \n",
    "    if i <= 50: return 50\n",
    "    if i > 50 and i <= 100: return i\n",
    "    if i > 100 and i <= 200: return i \n",
    "    if i > 200 and i <= 500: return i + 75\n",
    "    \n",
    "    if i > 500 and i <= 1000: return i + 125\n",
    "    if i > 1000 and i <= 1500: return i + 250\n",
    "    if i > 1500 and i <= 2000: return i + 500\n",
    "    if i > 2000: return 3000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e7749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "557c0e8c",
   "metadata": {},
   "source": [
    "### De-trending"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3b711f9",
   "metadata": {},
   "source": [
    "print(\"For each variable, plot with dim and date to visualize the trend\")\n",
    "# the variable list \n",
    "var_list = [\"scc\", \"mk_wgt\", \"min_time\", \"var_time\", \"milk_flow_max\", \"ft_pcnt\", \"pt_pcnt\", \"milkng_temp\", \"cow_info\", \"prep_time\", \"no_visit\"]\n",
    "\n",
    "print(\"Loop through the variable list and plot\")   \n",
    "for var_name in var_list:\n",
    "    df_plot = df.groupby('milkng_date_only').mean(numeric_only=True)[var_name]\n",
    "    #plt.show()\n",
    "    df_plot.plot()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(var_name)\n",
    "    plt.show()\n",
    "    print(\"==========\")\n",
    "\n",
    "    df_plot = df.groupby('dim').mean(numeric_only=True)[var_name]\n",
    "    #plt.show()\n",
    "    df_plot.plot()\n",
    "    plt.ylabel(var_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f29755",
   "metadata": {},
   "source": [
    "### Chunking for time-series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83543bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Given a dataset of a cow, find the start and end index of valid period (continous dim and the same period index) \n",
    "\n",
    "# 2. Given a valid period, chunk to X and y \n",
    "\n",
    "# 3. Use an overall function to loop through cows in a herd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bee1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Given a dataset of a cow, find the start and end index of valid period (continous dim and the same period index) \n",
    "\"\"\" \n",
    "func: \n",
    "    to find the start and end index of valid period \n",
    "args: \n",
    "    ls_dim: list[float] \n",
    "    ls_period_index: list[int] \n",
    "return: \n",
    "    ls_index: a list of start and end index of this cow: list[int]\n",
    "\"\"\"\n",
    "def find_valid_perod(ls_dim, ls_period_index): \n",
    "    \n",
    "    # check the length of ls_dim \n",
    "    if len(ls_dim) <= 2: \n",
    "        return [0, len(ls_dim)]\n",
    "        \n",
    "    # init result and append the start index\n",
    "    ls_index = [0]  \n",
    "    \n",
    "    # loop through the two input lists \n",
    "    for i in range(len(ls_dim)-1): \n",
    "        # if dim jumped or period index changed \n",
    "        if ((ls_dim[i+1] - 1) != ls_dim[i]) or (ls_period_index[i+1] != ls_period_index[i]): \n",
    "            # append new end index \n",
    "            ls_index.append(i) \n",
    "            \n",
    "    # check for the last element  \n",
    "    if (ls_dim[-1]-1 == ls_dim[-2]) and (ls_period_index[-1] == ls_period_index[-2]): \n",
    "        # append the last \n",
    "        ls_index.append(len(ls_dim))\n",
    "        \n",
    "    return ls_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31710405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Given a valid period, chunk to X and y \n",
    "\"\"\" \n",
    "func: \n",
    "    given a valid period, create \n",
    "    dataset for seq2seq models X, y \n",
    "args: \n",
    "    valid_period: dataframe (the target (scc_std) has index 0!)\n",
    "    X_len: int (length of input time period)\n",
    "    y_len: int (length of output time period)\n",
    "return: \n",
    "    don't return, keep appending ls_X, ls_y\n",
    "\"\"\"\n",
    "def chunk_to_X_y(valid_period, X_len, y_len, ls_X, ls_y):\n",
    "    \n",
    "    # check length \n",
    "    if valid_period.shape[0] < X_len + y_len: \n",
    "        return None\n",
    "\n",
    "    # loop by the rows (start, end, step)\n",
    "    for i in range(0, valid_period.shape[0]-X_len-y_len, y_len): \n",
    "        # append to X \n",
    "        ls_X.append(valid_period.iloc[i:i+X_len, :].to_numpy())\n",
    "        # append to y \n",
    "        ls_y.append(valid_period.iloc[i+X_len:i+X_len+y_len, 0].to_numpy())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3d09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use an overall function to loop through cows in a herd\n",
    "\"\"\" \n",
    "func: \n",
    "    loop through cows and chunking \n",
    "args: \n",
    "    df_stded: dataframe\n",
    "    ls_predictors: list of variables keeped in prediction (list[str])\n",
    "    X_len, y_len: the length of X and y (predictors and predicitons) (int, int)\n",
    "return: \n",
    "\n",
    "\"\"\"\n",
    "def chunk_herd(df_stded, ls_predictors):\n",
    "    \n",
    "    # list of cow id \n",
    "    ls_cow_id = df_stded['anm_ida'].unique().tolist() \n",
    "\n",
    "    # store valid_period \n",
    "    ls_df_period = []\n",
    "    \n",
    "    # looping cow id \n",
    "    for idx in ls_cow_id:\n",
    "        \n",
    "        # obtain cow data by index\n",
    "        df_cow = df_stded[df_stded['anm_ida']==idx]\n",
    "\n",
    "        \"\"\"using func: \"\"\"\n",
    "        ls_index = find_valid_perod(df_cow['dim'].tolist(), df_cow['period_index'].tolist())\n",
    "\n",
    "        # loop through ls_index for each valid period \n",
    "        for idx in range(len(ls_index)-1):\n",
    "        \n",
    "            # obtain a period from ls_index \n",
    "            valid_period = df_cow.iloc[ls_index[idx]:ls_index[idx+1], :]\n",
    "\n",
    "            # keep only the predictor variables\n",
    "            valid_period = valid_period[ls_predictors]\n",
    "        \n",
    "            # append to ls_df_period\n",
    "            ls_df_period.append(valid_period)\n",
    "            \n",
    "    return ls_df_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1aa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    to process a herd of data \n",
    "arg: \n",
    "    df_4: pd.Dataframe\n",
    "    var_list_dim: list to correct for dim (list[str])\n",
    "    var_list_date: list to correct for date (list[str])\n",
    "    X_len: int\n",
    "    y_len: int\n",
    "    ls_predictors: list of vars keep (list[str])\n",
    "    one_herd=True: boolean \n",
    "return: \n",
    "    ls_X: numpy 3d\n",
    "    ls_y: numpy 2d \n",
    "    scc_mean: int\n",
    "    scc_var: int\n",
    "\"\"\"\n",
    "def process_data_per_herd(df, var_list_dim, var_list_date, X_len, y_len, ls_predictors, one_herd=True):\n",
    "\n",
    "    if one_herd:\n",
    "        print(\"Put scc values in buckets to regulize regression model\")\n",
    "        \"\"\"using func: \"\"\"\n",
    "        df['scc_bucket']=df['scc'].apply(conditions)\n",
    "        print(\"check nan: \", df['scc_bucket'].isnull().sum())\n",
    "\n",
    "    print(\"Correcting for dim...\")\n",
    "    for var_name in var_list_dim:\n",
    "        # obtain the list of mean\n",
    "        mean = df.groupby('dim').mean(numeric_only=True)[var_name]\n",
    "        # convert to dictionary\n",
    "        dict_ = mean.to_dict()\n",
    "        # create new variable\n",
    "        df[var_name] = df.apply(lambda x: x[var_name] - dict_[x['dim']], axis=1)\n",
    "\n",
    "    print(\"Correcting for milkng_date_only...\")\n",
    "    for var_name in var_list_date:\n",
    "        # obtain the list of mean\n",
    "        mean = df.groupby('milkng_date_only').mean(numeric_only=True)[var_name]\n",
    "        # convert to dictionary\n",
    "        dict_ = mean.to_dict()\n",
    "        # create new variable\n",
    "        df[var_name] = df.apply(lambda x: x[var_name] - dict_[x['milkng_date_only']], axis=1)\n",
    "\n",
    "    # we can pick if to standardize from here or not \n",
    "    if one_herd:\n",
    "        print(\"Standardize SCC and storing\")\n",
    "        scc_var = df['scc_bucket'].std() \n",
    "        scc_mean = df['scc_bucket'].mean() \n",
    "        df[\"scc\"] = (df['scc_bucket'] - scc_mean) / scc_var\n",
    "        print(\"The mean and variance: \", scc_mean, scc_var)\n",
    "    else: \n",
    "        scc_mean, scc_var = -1, -1\n",
    "        print(\"Not standardizing scc per herd: \", scc_mean, scc_var)\n",
    "\n",
    "    # standardization: except for scc where we have already stded\n",
    "    for i in range(1, len(ls_predictors)): \n",
    "        df[ls_predictors[i]] = (df[ls_predictors[i]] - df[ls_predictors[i]].mean()) / df[ls_predictors[i]].std()\n",
    "\n",
    "    \"\"\"using func: \"\"\"\n",
    "    ls_X, ls_y = chunk_herd(df,  ls_predictors)\n",
    "    \n",
    "    return ls_X, ls_y, scc_mean, scc_var"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2b5a778",
   "metadata": {},
   "source": [
    "# init list with variables needed to be corrected by dim \n",
    "var_list_dim = [\"mk_wgt\", \"min_time\", \"milk_flow_max\", \"ft_pcnt\"]\n",
    "# init list with variables needed to be corrected by dim \n",
    "var_list_date = [\"milkng_temp\"]\n",
    "# X length is the length of input X \n",
    "X_len = 21\n",
    "# y length is the length of output y \n",
    "y_len = 5\n",
    "# a list of predictor variables: 1 target + 6 variables\n",
    "ls_predictors = [\"scc\", \"mk_wgt\", \"min_time\", \"milk_flow_max\", \"milkng_temp\", 'prep_time']\n",
    "\n",
    "\"\"\"using func: final_data_process\"\"\"\n",
    "df_4 = df[df['hrd_ida']==4]\n",
    "ls_X, ls_y, scc_mean, scc_var = process_data_per_herd(df_4, var_list_dim, var_list_date, X_len, y_len, ls_predictors, one_herd=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790fd5c",
   "metadata": {},
   "source": [
    "# Sequence to sequence regression for each period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb99691",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3b0d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb03963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    \n",
    "    layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)\n",
    "    x = layer(x, x)\n",
    " \n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    output_length,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    outputs = layers.Dense(output_length)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eca80ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    define model, split train&test, and evaluate\n",
    "args: \n",
    "    ls_X: numpy 3d\n",
    "    ls_y: numpy 2d\n",
    "    scc_mean: int\n",
    "    scc_var: int\n",
    "    EPOCHS: int\n",
    "return: \n",
    "    y_pred_value, y_test_value: numpy 2d\n",
    "    SP, SE, AUC: int\n",
    "\"\"\"\n",
    "def train_and_evaluate_herd(ls_X, ls_y, X_len, y_len, scc_mean, scc_var, len_ls_predictors, EPOCHS):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    print(\"Define model...\")\n",
    "    input_shape = ls_X[0].shape\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=64,\n",
    "        num_heads=2,\n",
    "        ff_dim=2,\n",
    "        num_transformer_blocks=2,\n",
    "        mlp_units=[32],\n",
    "        output_length = y_len,\n",
    "        mlp_dropout=0.25,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "    # split into training and testing\n",
    "    training_ratio = 0.8\n",
    "    # split and convert to numpy array format (required by tf)\n",
    "    train_set = (np.array(ls_X[:int(training_ratio*len(ls_X))]), np.array(ls_y[:int(training_ratio*len(ls_y))]))\n",
    "    test_set = (np.array(ls_X[int(training_ratio*len(ls_X)):]), np.array(ls_y[int(training_ratio*len(ls_y)):]))\n",
    "\n",
    "    print(\"Check length of X and y: \", len(ls_X), len(ls_y))\n",
    "    print(\"Check length of train and test: \", len(train_set[0]), len(test_set[0]))\n",
    "    print(\"training_ratio: \", training_ratio)\n",
    "\n",
    "    \"\"\"using func: \"\"\"\n",
    "    valid_mae, model, histroy = fit_and_evaluate(model, train_set, test_set, learning_rate=0.02, epochs=EPOCHS)\n",
    "\n",
    "    print(\"scc_mean, scc_var: \", scc_mean, scc_var)\n",
    "    print(\"Average error: \", scc_mean * valid_mae)\n",
    "\n",
    "    print(\"Making prediction...\")\n",
    "    y_pred = model.predict(test_set[0])\n",
    "    y_pred_value =  (y_pred * scc_var) + scc_mean\n",
    "    y_test_value = (test_set[1] * scc_var) + scc_mean\n",
    "    \n",
    "    # select scc_threshold based on herds\n",
    "    #threshold_ls = [scc_mean-0.75*scc_var, scc_mean-0.5*scc_var, scc_mean-0.25*scc_var, scc_mean, scc_mean+0.25*scc_var,  scc_mean+0.5*scc_var, scc_mean+0.75*scc_var]\n",
    "    #threshold_ls = [scc_mean-0.5*scc_var, scc_mean-0.4*scc_var, scc_mean-0.3*scc_var, scc_mean-0.2*scc_var, scc_mean-0.1*scc_var, scc_mean, scc_mean+0.1*scc_var, scc_mean+0.2*scc_var,  scc_mean+0.3*scc_var, scc_mean+0.4*scc_var, scc_mean+0.5*scc_var]\n",
    "    threshold_ls = [scc_mean]\n",
    "    performance_ls = [0.1, 0.1, 0.1]\n",
    "    # set init AUC \n",
    "    AUC_max = 0.1 \n",
    "    # looping for threshold \n",
    "    for i in threshold_ls:    \n",
    "        \"\"\"using func: regress_to_classify\"\"\"\n",
    "        SP, SE, AUC = regress_to_classify(y_test_value, y_pred_value, scc_threshold=i)\n",
    "        print(\"SP, SE, AUC: \", SP, SE, AUC)\n",
    "        # pick by AUC\n",
    "        if AUC >= AUC_max:\n",
    "            # append to performance\n",
    "            performance_ls = [SP, SE, AUC]\n",
    "            # reset AUC_max \n",
    "            AUC_max = AUC\n",
    "    \n",
    "    # end looping \n",
    "    print()\n",
    "    print(\"Final SP, SE, AUC: \", performance_ls)\n",
    "    \n",
    "    return y_pred_value, y_test_value, SP, SE, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73e51294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code â€“ defines a utility function we'll reuse several time\n",
    "\"\"\"\n",
    "func: \n",
    "    fit_and_evaluate\n",
    "args: \n",
    "    model: tf model\n",
    "    train_set: tuple(X_train, y_train)\n",
    "    valid_set: tuple(X_test, y_test)\n",
    "    learning_rate: float\n",
    "    epochs: int \n",
    "\"\"\"\n",
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=10):\n",
    "    \n",
    "    # set the early stopping \n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # set optimizers\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    \n",
    "    # fitting the model \n",
    "    history = model.fit(\n",
    "                    x = train_set[0], \n",
    "                    y = train_set[1],\n",
    "                    batch_size=128,\n",
    "                    validation_data=(valid_set[0], valid_set[1]), \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[early_stopping_cb])\n",
    "    \n",
    "    # compute the validation loss\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set[0], valid_set[1])\n",
    "    \n",
    "    return valid_mae, model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c66bf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    to evaluate regression by \n",
    "    converting to classification problem \n",
    "args: \n",
    "    y_test_value: numpy (number of period, length)\n",
    "    y_pred_value: numpy (number of period, length)\n",
    "    scc_threshold: the scc threshold set to pick out mastitis in the predicion set \n",
    "    buffer = 5: int (the delay of mastitis occurence)\n",
    "return: \n",
    "    SP, SE, AUC\n",
    "\"\"\"\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def regress_to_classify(test, pred, scc_threshold, buffer = 5): \n",
    "    \n",
    "    # set result y_pred as the num of rows (example)\n",
    "    y_pred = [0 for i in range(pred.shape[0])]\n",
    "    y_test = [0 for i in range(pred.shape[0])]\n",
    "\n",
    "    # loop rows \n",
    "    for i in range(pred.shape[0]): \n",
    "        one_pred = pred[i, -buffer:]\n",
    "        # set 1 in y_pred base on the threshold \n",
    "        if max(one_pred) >= scc_threshold: y_pred[i] = 1\n",
    "        one_test = test[i, -buffer:]\n",
    "        # set 1 in y_test base on the threshold \n",
    "        if max(one_test) >= 2500: y_test[i] = 1\n",
    "    \n",
    "    \"\"\"using sklearn\"\"\"\n",
    "    try:\n",
    "        # this func requie y_test to have at least two classes\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sp = tn / (tn + fp)\n",
    "        se = tp / (tp + fn)\n",
    "    except ValueError:\n",
    "        print(\"Invalid threshold\")\n",
    "        sp, se, auc = 0.1, 0.1, 0.1\n",
    "\n",
    "    print(\"sp, se, auc: \", sp, se, auc)\n",
    "    return sp, se, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71678447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466321ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7f14695",
   "metadata": {},
   "source": [
    "# Combine data-processing and prediction for herds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133977",
   "metadata": {},
   "source": [
    "### Training on individual herds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63902a0b",
   "metadata": {},
   "source": [
    "# list of hrd_ida \n",
    "ls_herd_ida = df[\"hrd_ida\"].unique().tolist()\n",
    "\n",
    "# to store the performance of all herds \n",
    "performance_ls = []\n",
    "\n",
    "# looping for each herd\n",
    "for i in ls_herd_ida:\n",
    "    # pick herd\n",
    "    df_herd = df[df[\"hrd_ida\"]==i]\n",
    "    print(\"herd id: \", i)\n",
    "    print(\"shape of the herd: \", df_herd.shape)\n",
    "\n",
    "    \"\"\"using func: \"\"\"\n",
    "    ls_X, ls_y, scc_mean, scc_var =  process_data_per_herd(df_herd, var_list_dim, var_list_date, X_len, y_len, ls_predictors)\n",
    "    #print(np.array(ls_X).shape, np.array(ls_y).shape)\n",
    "    \"\"\"using func: \"\"\"\n",
    "    _, _, accuracy, specificy, sensitivity, F1 = train_and_evaluate_herd(ls_X, ls_y, scc_mean, scc_var)\n",
    "    # append ls \n",
    "    performance_ls.append([accuracy, specificy, sensitivity, F1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e91b71ba",
   "metadata": {},
   "source": [
    "print(\"Pick the threshold selected by F1 score\")\n",
    "perdict_per_herd = np.array(performance_ls[:-1]).mean(axis=0)\n",
    "print(\"accuracy, specificy, sensitivity, F1: \") \n",
    "print(perdict_per_herd) # [0.93284846 0.95525248 0.55634179 0.4641099 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf96fc9",
   "metadata": {},
   "source": [
    "### Training all the herds together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41ce00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    the final function from dataframe to X, y \n",
    "args: \n",
    "    df: pd.Dataframe (raw df) \n",
    "    var_list_dim: list[str] \n",
    "    var_list_date: list[str] \n",
    "    X_len: int (input period) \n",
    "    y_len: int (output period) \n",
    "    ls_predictors: list[str]\n",
    "return: \n",
    "    ls_X_ls: np.array (examples, input period, variables)\n",
    "    ls_y_ls: np.array (examples, input period)\n",
    "    scc_mean, scc_var: float \n",
    "\"\"\"\n",
    "def process_all_herd(df, var_list_dim, var_list_date, X_len, y_len, ls_predictors):\n",
    "\n",
    "    \"\"\"using func: conditions\"\"\"\n",
    "    df['scc']=df['scc'].apply(conditions)\n",
    "    print(\"check nan: \", df['scc'].isnull().sum())\n",
    "\n",
    "    print(\"Correcting for dim...\")\n",
    "    for var_name in var_list_dim:\n",
    "        # obtain the list of mean\n",
    "        mean = df.groupby('dim').mean(numeric_only=True)[var_name]\n",
    "        # convert to dictionary\n",
    "        dict_ = mean.to_dict()\n",
    "        # create new variable\n",
    "        df[var_name] = df.apply(lambda x: x[var_name] - dict_[x['dim']], axis=1)\n",
    "\n",
    "    print(\"Correcting for milkng_date_only...\")\n",
    "    for var_name in var_list_date:\n",
    "        # obtain the list of mean\n",
    "        mean = df.groupby('milkng_date_only').mean(numeric_only=True)[var_name]\n",
    "        # convert to dictionary\n",
    "        dict_ = mean.to_dict()\n",
    "        # create new variable\n",
    "        df[var_name] = df.apply(lambda x: x[var_name] - dict_[x['milkng_date_only']], axis=1)\n",
    "\n",
    "    # we can pick if to standardize from here or not\n",
    "    scc_var = df['scc'].std() \n",
    "    scc_mean = df['scc'].mean() \n",
    "\n",
    "    # standardization:\n",
    "    for i in range(len(ls_predictors)): \n",
    "        df[ls_predictors[i]] = (df[ls_predictors[i]] - df[ls_predictors[i]].mean()) / df[ls_predictors[i]].std()\n",
    "\n",
    "    \"\"\"using func: \"\"\"\n",
    "    ls_df_valid = chunk_herd(df,  ls_predictors)\n",
    "\n",
    "    return ls_df_valid, scc_mean, scc_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43a16a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check nan:  0\n",
      "Correcting for dim...\n",
      "Correcting for milkng_date_only...\n"
     ]
    }
   ],
   "source": [
    "# init list with variables needed to be corrected by dim \n",
    "var_list_dim = [\"mk_wgt\", \"min_time\", \"milk_flow_max\", \"ft_pcnt\"]\n",
    "# init list with variables needed to be corrected by dim \n",
    "var_list_date = [\"milkng_temp\"]\n",
    "# a list of predictor variables: 1 target + 6 variables\n",
    "ls_predictors = ['scc', 'mk_wgt', 'min_time', 'milk_flow_max', 'ft_pcnt', 'milkng_temp']\n",
    "# X length is the length of input X \n",
    "X_len = 21\n",
    "# y length is the length of output y \n",
    "y_len = 5\n",
    "\n",
    "\"\"\"using func: \"\"\"\n",
    "# to prevent in-place change \n",
    "df_new = df\n",
    "ls_df_valid, scc_mean, scc_var = process_all_herd(df_new, var_list_dim, var_list_date, X_len, y_len, ls_predictors)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2c18b7d",
   "metadata": {},
   "source": [
    "# X length is the length of input X \n",
    "X_len = 21\n",
    "# y length is the length of output y \n",
    "y_len = 5\n",
    "\n",
    "ls_X, ls_y = [], [] \n",
    "for i in range(len(ls_df_valid)): \n",
    "    valid_period = ls_df_valid[i]\n",
    "    chunk_to_X_y(valid_period, X_len, y_len, ls_X, ls_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "104678a7",
   "metadata": {},
   "source": [
    "\"\"\"using func: train_and_evaluate_herd\"\"\"\n",
    "_, _, SP, SE, AUC = train_and_evaluate_herd(ls_X, ls_y, X_len, y_len, scc_mean, scc_var, len(ls_predictors), EPOCHS=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993c88f",
   "metadata": {},
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b284cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "X_len, y_len:  21 5\n",
      "Define model...\n",
      "Check length of X and y:  81403 81403\n",
      "Check length of train and test:  65122 16281\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "509/509 [==============================] - 39s 70ms/step - loss: 0.1975 - mae: 0.3818 - val_loss: 0.1724 - val_mae: 0.3295\n",
      "Epoch 2/10\n",
      "509/509 [==============================] - 35s 69ms/step - loss: 0.1715 - mae: 0.3278 - val_loss: 0.1688 - val_mae: 0.3191\n",
      "Epoch 3/10\n",
      "509/509 [==============================] - 35s 68ms/step - loss: 0.1683 - mae: 0.3209 - val_loss: 0.1660 - val_mae: 0.3155\n",
      "Epoch 4/10\n",
      "509/509 [==============================] - 35s 69ms/step - loss: 0.1671 - mae: 0.3194 - val_loss: 0.1654 - val_mae: 0.3178\n",
      "Epoch 5/10\n",
      "509/509 [==============================] - 34s 68ms/step - loss: 0.1659 - mae: 0.3172 - val_loss: 0.1641 - val_mae: 0.3188\n",
      "Epoch 6/10\n",
      "509/509 [==============================] - 36s 72ms/step - loss: 0.1652 - mae: 0.3158 - val_loss: 0.1645 - val_mae: 0.3343\n",
      "Epoch 7/10\n",
      "509/509 [==============================] - 35s 69ms/step - loss: 0.1643 - mae: 0.3151 - val_loss: 0.1631 - val_mae: 0.3222\n",
      "Epoch 8/10\n",
      "509/509 [==============================] - 35s 69ms/step - loss: 0.1642 - mae: 0.3145 - val_loss: 0.1638 - val_mae: 0.3092\n",
      "Epoch 9/10\n",
      "509/509 [==============================] - 35s 70ms/step - loss: 0.1636 - mae: 0.3130 - val_loss: 0.1622 - val_mae: 0.3265\n",
      "Epoch 10/10\n",
      "509/509 [==============================] - 47s 92ms/step - loss: 0.1624 - mae: 0.3114 - val_loss: 0.1615 - val_mae: 0.3191\n",
      "509/509 [==============================] - 5s 10ms/step - loss: 0.1615 - mae: 0.3191\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  81.9496404740068\n",
      "Making prediction...\n",
      "509/509 [==============================] - 7s 13ms/step\n",
      "sp, se, auc:  0.8738897596656218 0.8121775025799793 0.8430336311228006\n",
      "SP, SE, AUC:  0.8738897596656218 0.8121775025799793 0.8430336311228006\n",
      "\n",
      "Final SP, SE, AUC:  [0.8738897596656218, 0.8121775025799793, 0.8430336311228006]\n",
      "========================================\n",
      "X_len, y_len:  28 5\n",
      "Define model...\n",
      "Check length of X and y:  69648 69648\n",
      "Check length of train and test:  55718 13930\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "436/436 [==============================] - 77s 161ms/step - loss: 0.1994 - mae: 0.3880 - val_loss: 0.1714 - val_mae: 0.3323\n",
      "Epoch 2/10\n",
      "436/436 [==============================] - 38s 86ms/step - loss: 0.1757 - mae: 0.3354 - val_loss: 0.1679 - val_mae: 0.3269\n",
      "Epoch 3/10\n",
      "436/436 [==============================] - 37s 86ms/step - loss: 0.1718 - mae: 0.3280 - val_loss: 0.1663 - val_mae: 0.3164\n",
      "Epoch 4/10\n",
      "436/436 [==============================] - 38s 88ms/step - loss: 0.1699 - mae: 0.3241 - val_loss: 0.1658 - val_mae: 0.3179\n",
      "Epoch 5/10\n",
      "436/436 [==============================] - 38s 87ms/step - loss: 0.1685 - mae: 0.3219 - val_loss: 0.1635 - val_mae: 0.3207\n",
      "Epoch 6/10\n",
      "436/436 [==============================] - 38s 87ms/step - loss: 0.1669 - mae: 0.3188 - val_loss: 0.1621 - val_mae: 0.3138\n",
      "Epoch 7/10\n",
      "436/436 [==============================] - 37s 85ms/step - loss: 0.1656 - mae: 0.3168 - val_loss: 0.1610 - val_mae: 0.3214\n",
      "Epoch 8/10\n",
      "436/436 [==============================] - 37s 84ms/step - loss: 0.1651 - mae: 0.3149 - val_loss: 0.1600 - val_mae: 0.3093\n",
      "Epoch 9/10\n",
      "436/436 [==============================] - 37s 85ms/step - loss: 0.1643 - mae: 0.3141 - val_loss: 0.1609 - val_mae: 0.3055\n",
      "Epoch 10/10\n",
      "436/436 [==============================] - 37s 85ms/step - loss: 0.1638 - mae: 0.3134 - val_loss: 0.1592 - val_mae: 0.3191\n",
      "436/436 [==============================] - 5s 11ms/step - loss: 0.1592 - mae: 0.3191\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  81.96515644784364\n",
      "Making prediction...\n",
      "436/436 [==============================] - 5s 10ms/step\n",
      "sp, se, auc:  0.8769747386094787 0.8331318016928658 0.8550532701511722\n",
      "SP, SE, AUC:  0.8769747386094787 0.8331318016928658 0.8550532701511722\n",
      "\n",
      "Final SP, SE, AUC:  [0.8769747386094787, 0.8331318016928658, 0.8550532701511722]\n",
      "========================================\n",
      "X_len, y_len:  35 5\n",
      "Define model...\n",
      "Check length of X and y:  59418 59418\n",
      "Check length of train and test:  47534 11884\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "372/372 [==============================] - 44s 110ms/step - loss: 0.1988 - mae: 0.3854 - val_loss: 0.1695 - val_mae: 0.3297\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 40s 106ms/step - loss: 0.1758 - mae: 0.3363 - val_loss: 0.1628 - val_mae: 0.3222\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 40s 108ms/step - loss: 0.1708 - mae: 0.3277 - val_loss: 0.1608 - val_mae: 0.3162\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 40s 108ms/step - loss: 0.1694 - mae: 0.3247 - val_loss: 0.1609 - val_mae: 0.3141\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 40s 107ms/step - loss: 0.1682 - mae: 0.3227 - val_loss: 0.1603 - val_mae: 0.3188\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 37s 99ms/step - loss: 0.1670 - mae: 0.3201 - val_loss: 0.1581 - val_mae: 0.3227\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 41s 110ms/step - loss: 0.1661 - mae: 0.3189 - val_loss: 0.1589 - val_mae: 0.3120\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 40s 109ms/step - loss: 0.1655 - mae: 0.3170 - val_loss: 0.1590 - val_mae: 0.3128\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 40s 108ms/step - loss: 0.1642 - mae: 0.3153 - val_loss: 0.1563 - val_mae: 0.3114\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 40s 109ms/step - loss: 0.1637 - mae: 0.3143 - val_loss: 0.1579 - val_mae: 0.3132\n",
      "372/372 [==============================] - 4s 11ms/step - loss: 0.1579 - mae: 0.3132\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  80.43674499644897\n",
      "Making prediction...\n",
      "372/372 [==============================] - 4s 11ms/step\n",
      "sp, se, auc:  0.8723765294275252 0.834061135371179 0.853218832399352\n",
      "SP, SE, AUC:  0.8723765294275252 0.834061135371179 0.853218832399352\n",
      "\n",
      "Final SP, SE, AUC:  [0.8723765294275252, 0.834061135371179, 0.853218832399352]\n",
      "========================================\n",
      "X_len, y_len:  21 8\n",
      "Define model...\n",
      "Check length of X and y:  49336 49336\n",
      "Check length of train and test:  39468 9868\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "309/309 [==============================] - 26s 72ms/step - loss: 0.2017 - mae: 0.3979 - val_loss: 0.1785 - val_mae: 0.3525\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 22s 70ms/step - loss: 0.1773 - mae: 0.3425 - val_loss: 0.1730 - val_mae: 0.3415\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 22s 71ms/step - loss: 0.1728 - mae: 0.3309 - val_loss: 0.1757 - val_mae: 0.3375\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 23s 73ms/step - loss: 0.1704 - mae: 0.3250 - val_loss: 0.1693 - val_mae: 0.3278\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 21s 69ms/step - loss: 0.1692 - mae: 0.3216 - val_loss: 0.1678 - val_mae: 0.3263\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 18s 59ms/step - loss: 0.1689 - mae: 0.3210 - val_loss: 0.1666 - val_mae: 0.3231\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 22s 71ms/step - loss: 0.1679 - mae: 0.3189 - val_loss: 0.1666 - val_mae: 0.3328\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 22s 71ms/step - loss: 0.1660 - mae: 0.3160 - val_loss: 0.1653 - val_mae: 0.3216\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 21s 69ms/step - loss: 0.1658 - mae: 0.3158 - val_loss: 0.1648 - val_mae: 0.3166\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 21s 69ms/step - loss: 0.1656 - mae: 0.3147 - val_loss: 0.1640 - val_mae: 0.3182\n",
      "309/309 [==============================] - 2s 8ms/step - loss: 0.1640 - mae: 0.3182\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  81.72741069974369\n",
      "Making prediction...\n",
      "309/309 [==============================] - 3s 8ms/step\n",
      "sp, se, auc:  0.8698600645855759 0.7906574394463668 0.8302587520159713\n",
      "SP, SE, AUC:  0.8698600645855759 0.7906574394463668 0.8302587520159713\n",
      "\n",
      "Final SP, SE, AUC:  [0.8698600645855759, 0.7906574394463668, 0.8302587520159713]\n",
      "========================================\n",
      "X_len, y_len:  28 8\n",
      "Define model...\n",
      "Check length of X and y:  42005 42005\n",
      "Check length of train and test:  33604 8401\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 26s 87ms/step - loss: 0.2130 - mae: 0.4193 - val_loss: 0.1801 - val_mae: 0.3413\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.1806 - mae: 0.3478 - val_loss: 0.1715 - val_mae: 0.3390\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.1773 - mae: 0.3392 - val_loss: 0.1701 - val_mae: 0.3276\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.1758 - mae: 0.3349 - val_loss: 0.1690 - val_mae: 0.3307\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 22s 86ms/step - loss: 0.1743 - mae: 0.3315 - val_loss: 0.1675 - val_mae: 0.3227\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.1730 - mae: 0.3294 - val_loss: 0.1673 - val_mae: 0.3201\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.1719 - mae: 0.3272 - val_loss: 0.1681 - val_mae: 0.3315\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.1720 - mae: 0.3266 - val_loss: 0.1653 - val_mae: 0.3214\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.1710 - mae: 0.3252 - val_loss: 0.1649 - val_mae: 0.3225\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.1708 - mae: 0.3241 - val_loss: 0.1636 - val_mae: 0.3198\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.1636 - mae: 0.3198\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  82.12829233063144\n",
      "Making prediction...\n",
      "263/263 [==============================] - 3s 9ms/step\n",
      "sp, se, auc:  0.8852811118130133 0.7860082304526749 0.8356446711328441\n",
      "SP, SE, AUC:  0.8852811118130133 0.7860082304526749 0.8356446711328441\n",
      "\n",
      "Final SP, SE, AUC:  [0.8852811118130133, 0.7860082304526749, 0.8356446711328441]\n",
      "========================================\n",
      "X_len, y_len:  35 8\n",
      "Define model...\n",
      "Check length of X and y:  35816 35816\n",
      "Check length of train and test:  28652 7164\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "224/224 [==============================] - 33s 129ms/step - loss: 0.2179 - mae: 0.4261 - val_loss: 0.1770 - val_mae: 0.3444\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 26s 117ms/step - loss: 0.1862 - mae: 0.3571 - val_loss: 0.1743 - val_mae: 0.3410\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.1821 - mae: 0.3468 - val_loss: 0.1717 - val_mae: 0.3308\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 27s 122ms/step - loss: 0.1789 - mae: 0.3399 - val_loss: 0.1681 - val_mae: 0.3300\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.1771 - mae: 0.3366 - val_loss: 0.1664 - val_mae: 0.3270\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 27s 120ms/step - loss: 0.1761 - mae: 0.3342 - val_loss: 0.1685 - val_mae: 0.3266\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 26s 118ms/step - loss: 0.1744 - mae: 0.3315 - val_loss: 0.1661 - val_mae: 0.3223\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 28s 126ms/step - loss: 0.1738 - mae: 0.3299 - val_loss: 0.1652 - val_mae: 0.3240\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 27s 121ms/step - loss: 0.1727 - mae: 0.3280 - val_loss: 0.1667 - val_mae: 0.3222\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.1724 - mae: 0.3278 - val_loss: 0.1658 - val_mae: 0.3184\n",
      "224/224 [==============================] - 4s 17ms/step - loss: 0.1658 - mae: 0.3184\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  81.78305999909932\n",
      "Making prediction...\n",
      "224/224 [==============================] - 3s 13ms/step\n",
      "sp, se, auc:  0.8904882029974773 0.7929411764705883 0.8417146897340327\n",
      "SP, SE, AUC:  0.8904882029974773 0.7929411764705883 0.8417146897340327\n",
      "\n",
      "Final SP, SE, AUC:  [0.8904882029974773, 0.7929411764705883, 0.8417146897340327]\n",
      "========================================\n",
      "X_len, y_len:  21 10\n",
      "Define model...\n",
      "Check length of X and y:  38374 38374\n",
      "Check length of train and test:  30699 7675\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 24s 84ms/step - loss: 0.2191 - mae: 0.4277 - val_loss: 0.1824 - val_mae: 0.3541\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.1840 - mae: 0.3561 - val_loss: 0.1771 - val_mae: 0.3442\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 0.1799 - mae: 0.3445 - val_loss: 0.1748 - val_mae: 0.3326\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.1777 - mae: 0.3380 - val_loss: 0.1736 - val_mae: 0.3357\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.1757 - mae: 0.3345 - val_loss: 0.1718 - val_mae: 0.3284\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.1744 - mae: 0.3313 - val_loss: 0.1707 - val_mae: 0.3257\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.1737 - mae: 0.3295 - val_loss: 0.1701 - val_mae: 0.3284\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.1729 - mae: 0.3275 - val_loss: 0.1693 - val_mae: 0.3307\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.1710 - mae: 0.3249 - val_loss: 0.1691 - val_mae: 0.3263\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.1715 - mae: 0.3248 - val_loss: 0.1689 - val_mae: 0.3261\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.1689 - mae: 0.3261\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  83.76221546597633\n",
      "Making prediction...\n",
      "240/240 [==============================] - 3s 10ms/step\n",
      "sp, se, auc:  0.8812361419068736 0.7734204793028322 0.8273283106048529\n",
      "SP, SE, AUC:  0.8812361419068736 0.7734204793028322 0.8273283106048529\n",
      "\n",
      "Final SP, SE, AUC:  [0.8812361419068736, 0.7734204793028322, 0.8273283106048529]\n",
      "========================================\n",
      "X_len, y_len:  28 10\n",
      "Define model...\n",
      "Check length of X and y:  33091 33091\n",
      "Check length of train and test:  26472 6619\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "207/207 [==============================] - 24s 100ms/step - loss: 0.2241 - mae: 0.4417 - val_loss: 0.1841 - val_mae: 0.3643\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 19s 92ms/step - loss: 0.1883 - mae: 0.3669 - val_loss: 0.1779 - val_mae: 0.3584\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 20s 95ms/step - loss: 0.1821 - mae: 0.3509 - val_loss: 0.1755 - val_mae: 0.3428\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 19s 91ms/step - loss: 0.1790 - mae: 0.3430 - val_loss: 0.1716 - val_mae: 0.3414\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 19s 93ms/step - loss: 0.1764 - mae: 0.3371 - val_loss: 0.1704 - val_mae: 0.3369\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 19s 94ms/step - loss: 0.1753 - mae: 0.3336 - val_loss: 0.1705 - val_mae: 0.3420\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 19s 93ms/step - loss: 0.1736 - mae: 0.3305 - val_loss: 0.1678 - val_mae: 0.3268\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 20s 96ms/step - loss: 0.1733 - mae: 0.3299 - val_loss: 0.1680 - val_mae: 0.3398\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 20s 94ms/step - loss: 0.1730 - mae: 0.3284 - val_loss: 0.1669 - val_mae: 0.3334\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 21s 100ms/step - loss: 0.1726 - mae: 0.3269 - val_loss: 0.1673 - val_mae: 0.3375\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.1673 - mae: 0.3375\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  86.68395677513034\n",
      "Making prediction...\n",
      "207/207 [==============================] - 2s 9ms/step\n",
      "sp, se, auc:  0.8677911646586345 0.7791878172588832 0.8234894909587588\n",
      "SP, SE, AUC:  0.8677911646586345 0.7791878172588832 0.8234894909587588\n",
      "\n",
      "Final SP, SE, AUC:  [0.8677911646586345, 0.7791878172588832, 0.8234894909587588]\n",
      "========================================\n",
      "X_len, y_len:  35 10\n",
      "Define model...\n",
      "Check length of X and y:  27949 27949\n",
      "Check length of train and test:  22359 5590\n",
      "training_ratio:  0.8\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 25s 123ms/step - loss: 0.2336 - mae: 0.4556 - val_loss: 0.1810 - val_mae: 0.3607\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 19s 111ms/step - loss: 0.1907 - mae: 0.3719 - val_loss: 0.1757 - val_mae: 0.3511\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.1872 - mae: 0.3600 - val_loss: 0.1726 - val_mae: 0.3473\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 0.1832 - mae: 0.3517 - val_loss: 0.1730 - val_mae: 0.3453\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 0.1815 - mae: 0.3466 - val_loss: 0.1713 - val_mae: 0.3311\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 0.1797 - mae: 0.3422 - val_loss: 0.1717 - val_mae: 0.3338\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.1780 - mae: 0.3386 - val_loss: 0.1694 - val_mae: 0.3258\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 0.1771 - mae: 0.3360 - val_loss: 0.1657 - val_mae: 0.3246\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 20s 112ms/step - loss: 0.1771 - mae: 0.3361 - val_loss: 0.1670 - val_mae: 0.3185\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.1758 - mae: 0.3340 - val_loss: 0.1646 - val_mae: 0.3296\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.1646 - mae: 0.3296\n",
      "scc_mean, scc_var:  256.84740454970324 537.2763125617959\n",
      "Average error:  84.65202250233075\n",
      "Making prediction...\n",
      "175/175 [==============================] - 2s 12ms/step\n",
      "sp, se, auc:  0.865781990521327 0.8444444444444444 0.8551132174828857\n",
      "SP, SE, AUC:  0.865781990521327 0.8444444444444444 0.8551132174828857\n",
      "\n",
      "Final SP, SE, AUC:  [0.865781990521327, 0.8444444444444444, 0.8551132174828857]\n",
      "[[0.8738897596656218, 0.8121775025799793, 0.8430336311228006], [0.8769747386094787, 0.8331318016928658, 0.8550532701511722], [0.8723765294275252, 0.834061135371179, 0.853218832399352], [0.8698600645855759, 0.7906574394463668, 0.8302587520159713], [0.8852811118130133, 0.7860082304526749, 0.8356446711328441], [0.8904882029974773, 0.7929411764705883, 0.8417146897340327], [0.8812361419068736, 0.7734204793028322, 0.8273283106048529], [0.8677911646586345, 0.7791878172588832, 0.8234894909587588], [0.865781990521327, 0.8444444444444444, 0.8551132174828857]]\n"
     ]
    }
   ],
   "source": [
    "# init result_ls \n",
    "result_ls = [] \n",
    "# X length is the length of input X, y length is the length of output y \n",
    "ls_X_len_y_len = [(21, 5), (28, 5), (35, 5), (21, 8), (28, 8), (35, 8), (21, 10), (28, 10), (35, 10)]\n",
    "\n",
    "for pair in ls_X_len_y_len:\n",
    "    X_len, y_len = pair[0], pair[1]\n",
    "    print(\"========================================\")\n",
    "    print(\"X_len, y_len: \", X_len, y_len)\n",
    "    \n",
    "    # init X, y\n",
    "    ls_X, ls_y = [], [] \n",
    "    # looping ls_df_valid (list[df])\n",
    "    for i in range(len(ls_df_valid)): \n",
    "        # obtain period\n",
    "        valid_period = ls_df_valid[i]\n",
    "        \"\"\"using func: \"\"\"\n",
    "        chunk_to_X_y(valid_period, X_len, y_len, ls_X, ls_y)\n",
    "        \n",
    "    # here \n",
    "    \"\"\"using func: train_and_evaluate_herd\"\"\"\n",
    "    _, _, SP, SE, AUC = train_and_evaluate_herd(ls_X, ls_y, X_len, y_len, scc_mean, scc_var, len(ls_predictors), EPOCHS=10)\n",
    "    result_ls.append([SP, SE, AUC])\n",
    "\n",
    "print(result_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88be1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ls = [[0.8738897596656218, 0.8121775025799793, 0.8430336311228006], [0.8769747386094787, 0.8331318016928658, 0.8550532701511722], [0.8723765294275252, 0.834061135371179, 0.853218832399352], [0.8698600645855759, 0.7906574394463668, 0.8302587520159713], [0.8852811118130133, 0.7860082304526749, 0.8356446711328441], [0.8904882029974773, 0.7929411764705883, 0.8417146897340327], [0.8812361419068736, 0.7734204793028322, 0.8273283106048529], [0.8677911646586345, 0.7791878172588832, 0.8234894909587588], [0.865781990521327, 0.8444444444444444, 0.8551132174828857]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160044e",
   "metadata": {},
   "source": [
    "### Plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "285e9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    to write the label on plots \n",
    "args: \n",
    "    dates, temp: list of x and y in the plot \n",
    "    plt: the plot object\n",
    "return: \n",
    "    annotated plot\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def write_label(dates, temp, plt): \n",
    "    for x, y in zip(dates, temp):\n",
    "        label = y\n",
    "        plt.annotate(label, (x, y),\n",
    "                     xycoords=\"data\",\n",
    "                     textcoords=\"offset points\",\n",
    "                     xytext=(0, 10), ha=\"center\")\n",
    "\n",
    "\"\"\" \n",
    "func: \n",
    "    to plot for a model's result \n",
    "args: \n",
    "    log_ls: list[list[float]] the results of this model\n",
    "    model_name: str\n",
    "    path: str\n",
    "return: \n",
    "    name_ls: list[str]\n",
    "\"\"\"\n",
    "def plot_one_model(log_ls, model_name, path):\n",
    "    \n",
    "    from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "\n",
    "    # init methods\n",
    "    method_str = [' 21 days', ' 28 days', '35 days']\n",
    "    # init method id (0, 1, 2)\n",
    "    idx_method_ls = [0, 1, 2]\n",
    "    # total num of methods\n",
    "    shrink_method = 3 \n",
    "    # init name \n",
    "    name_ls = []\n",
    "\n",
    "    # looping for idx_method \n",
    "    for idx_method in idx_method_ls: \n",
    "\n",
    "        # init list for SP, SE, AUC \n",
    "        SP, SE, AUC = [], [], [] \n",
    "\n",
    "        # loop the list \n",
    "        for i in range(idx_method, len(log_ls), shrink_method):\n",
    "            # specificity\n",
    "            sp = round(log_ls[i][0]*100, 2)\n",
    "            SP.append(sp)\n",
    "            # sensitifity\n",
    "            se = round(log_ls[i][1]*100, 2)\n",
    "            SE.append(se)\n",
    "            # auc\n",
    "            auc = round(log_ls[i][2]*100, 2)\n",
    "            AUC.append(auc)   \n",
    "\n",
    "        # reserse the list\n",
    "        SP, SE, AUC = SP[::-1], SE[::-1], AUC[::-1]\n",
    "        x_axis = ['5 days', '3 days', '1 days']\n",
    "\n",
    "        plt.plot(x_axis, SP, label = 'specificity', color=\"indigo\", marker = 'o')\n",
    "        \"\"\"using func: \"\"\"\n",
    "        write_label(x_axis, SP, plt)\n",
    "        plt.plot(x_axis, SE, label = 'sensitivity', color=\"indigo\", marker = 's')\n",
    "        \"\"\"using func: \"\"\"\n",
    "        write_label(x_axis, SE, plt)\n",
    "        plt.plot(x_axis, AUC, label = 'AUC', color=\"forestgreen\", marker = '^')\n",
    "        \"\"\"using func: \"\"\"\n",
    "        write_label(x_axis, AUC, plt)\n",
    "        plt.legend() \n",
    "        plt.title(model_name + \" with input length: \" + method_str[idx_method])\n",
    "        plt.xlabel(\"Days before the threshold\")\n",
    "        \n",
    "        # saving \n",
    "        name = model_name + \"_\" + method_str[idx_method]\n",
    "        name_ls.append(name)\n",
    "        plt.gcf().set_size_inches(5, 5)\n",
    "        plt.savefig(path+name, dpi=200)\n",
    "        plt.close()\n",
    "        \n",
    "    return name_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "330bf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ls = plot_one_model(result_ls, 'Transformers', 'plot/Results_regression_new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd2fc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "func: \n",
    "    concate plots \n",
    "args: \n",
    "    name_ls_log, name_ls_tree, name_ls_mlp: list[str]\n",
    "return: \n",
    "    a plot\n",
    "\"\"\"\n",
    "def concat_plots(name_ls, path, name):\n",
    "    \n",
    "    temp = name_ls\n",
    "    figa = plt.imread(path + temp[0] + '.png')\n",
    "    figb = plt.imread(path + temp[1] + '.png')\n",
    "    figc = plt.imread(path + temp[2] + '.png')\n",
    "    figd = np.concatenate((figa,figb), axis=0)\n",
    "    fige = np.concatenate((figd,figc), axis=0) \n",
    "                   \n",
    "    fname = path + name + \".png\"\n",
    "    plt.imsave(fname, fige)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cb1678f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concat_plots(name_ls, 'plot/Results_regression_new/', 'transformers_longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5efe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
